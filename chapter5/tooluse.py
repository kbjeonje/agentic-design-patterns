#  pip install langchain-classic
import os
import asyncio
from typing import List

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langchain_classic.agents import AgentExecutor, create_tool_calling_agent

os.environ["GOOGLE_API_KEY"] = ""

try:
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)
    print(f"âœ… Language model initialized: {llm.model}")
except Exception as e:
    print(f"ğŸ›‘ Error initializing language model: {e}")
    llm = None

# --- Define a Tool ---
# tool ë°ì½”ë ˆì´í„°: ì´ í•¨ìˆ˜ê°€ AIê°€ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” íŠ¹ìˆ˜í•œ ë„êµ¬ì„ì„ LangChainì— ì•Œë ¤ì¤Œ
@tool
def search_information(query: str) -> str:
    """
    Provides factual information on a given topic. Use this tool to find answers to questions
    like 'What is the capital of France?' or 'What is the weather in London?'.
    """
    print(f"\n--- ğŸ› ï¸ Tool Called: search_information with query: '{query}' ---")
    # Simulate a search tool with a dictionary of predefined results.
    simulated_results = {
        "weather in london": "The weather in London is currently cloudy with a temperature of 15Â°C.",
        "capital of france": "The capital of France is Paris.",
        "population of earth": "The estimated population of Earth is around 8 billion people.",
        "tallest mountain": "Mount Everest is the tallest mountain above sea level.",
        "default": f"Simulated search result for '{query}': No specific information found, but the topic seems interesting."
    }
    result = simulated_results.get(query.lower(), simulated_results["default"])
    print(f"--- TOOL RESULT: {result} ---")
    return result

tools = [search_information]


# --- Create a Tool-Calling Agent ---
if llm:
    # This prompt template requires an `agent_scratchpad` placeholder for the agent's internal steps.'
    # agent_scratchpad: AI ëª¨ë¸(LLM)ì´ ë¬¸ì œë¥¼ í•´ê²°í•  ë•Œ, ë°”ë¡œ ì •ë‹µì„ ë‚´ë†“ëŠ” ê²Œ ì•„ë‹ˆë¼ "ìƒê°ì˜ ê³¼ì •"ì„ ì ì–´ë‘ëŠ” ì„ì‹œ ë©”ëª¨ì¥ ê°™ì€ ê³µê°„
    # ì¦‰, ì—ì´ì „íŠ¸ê°€ ì–´ë–¤ ë„êµ¬ë¥¼ ì“¸ì§€ ê³ ë¯¼í•˜ê³ , ë„êµ¬ë¥¼ ì‹¤í–‰í•œ ê²°ê³¼ê°’ì„ ë°›ì•„ë³´ê³ , ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•˜ëŠ” ëª¨ë“  ì¤‘ê°„ ë‹¨ê³„ì˜ í…ìŠ¤íŠ¸ê°€ ì´ {agent_scratchpad}ë¼ëŠ” ë³€ìˆ˜ì— ì°¨ê³¡ì°¨ê³¡ ìŒ“ì´ê²Œ ë¨
    # placeholder: ì²˜ìŒ AIì—ê²Œ ì§ˆë¬¸ì„ ë˜ì§ˆ ë•ŒëŠ” ì´ ë¶€ë¶„ì´ ë¹„ì–´ìˆì§€ë§Œ, AIê°€ "ì–´ë”” ë³´ì, ê³„ì‚°ê¸°ë¥¼ ì¨ì•¼ê² êµ°" í•˜ê³  í–‰ë™ì„ ì‹œì‘í•˜ë©´ ê·¸ ê¸°ë¡ì´ ì´ ìë¦¬ì— ì‹¤ì‹œê°„ìœ¼ë¡œ ì±„ì›Œì§
    agent_prompt = ChatPromptTemplate.from_messages([
        ("system", "You are a helpful assistant."),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ])

    # Create the agent, binding the LLM, tools, and prompt together.
    # create_tool_calling_agent: ëª¨ë¸ì´ ë„êµ¬ë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ê°–ì¶”ë„ë¡ ì—°ê²°
    agent = create_tool_calling_agent(llm, tools, agent_prompt)

    # AgentExecutor is the runtime that invokes the agent and executes the chosen tools.
    # The 'tools' argument is not needed here as they are already bound to the agent.
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)


    async def run_agent_with_tool(query: str):
        """Invokes the agent executor with a query and prints the final response."""
        print(f"\n--- ğŸƒ Running Agent with Query: '{query}' ---")
        try:
            response = await agent_executor.ainvoke({"input": query})
            print("\n--- âœ… Final Agent Response ---")
            print(response["output"])
        except Exception as e:
            print(f"\nğŸ›‘ An error occurred during agent execution: {e}")

    async def main():
        """Runs all agent queries concurrently."""
        tasks = [
            run_agent_with_tool("What is the capital of France?"),
            run_agent_with_tool("What's the weather like in London?"),
            run_agent_with_tool("Tell me something about dogs.") # Should trigger the default tool response
        ]
        await asyncio.gather(*tasks) # asyncio.gather(*tasks) ë¶€ë¶„ì€ ì„¸ ê°€ì§€ ì§ˆë¬¸ì„ ë™ì‹œì—(ë³‘ë ¬ë¡œ) ì²˜ë¦¬í•˜ë¼ëŠ” ëœ»

    # Removed if __name__ == "__main__" block and directly await main()
    await main()

else:
    print("\nSkipping agent execution due to LLM initialization failure.")